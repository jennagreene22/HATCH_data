{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f95021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import country_converter as coco\n",
    "import string\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a965a148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/jennagreene/Documents/GitHub/HATCH_data/reading_files\n"
     ]
    }
   ],
   "source": [
    "## Get current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "## Find path to raw data (for the raw files)\n",
    "raw_data_path_usgs = os.path.abspath(os.path.join(os.getcwd(), '..', 'raw_data/usgs'))\n",
    "\n",
    "## Find path to folder for saving cleaned csv\n",
    "cleaned_data_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'cleaned_data'))\n",
    "\n",
    "\n",
    "## Find path to folder for inflation\n",
    "inflation_data_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'inflation'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34c3a686",
   "metadata": {},
   "source": [
    "Data sources:\n",
    "- https://www.usgs.gov/centers/national-minerals-information-center/historical-global-statistics-mineral-and-material\n",
    "- Data Series 896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0908e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_usgs_896(tech_name, file_name, sheet_name=0):\n",
    "    # Read Excel file into DataFrame\n",
    "    df = pd.read_excel(file_name, sheet_name=sheet_name, header=3,\n",
    "                       na_values=['XX','--', 'W', '(3/)', '(4/)','-- '])\n",
    "    \n",
    "    # Drop rows with irrelevant country names\n",
    "    drop_idx = []\n",
    "    for idx in df.index:\n",
    "        country = df[df.columns[0]].iloc[idx]\n",
    "        drop_list = ['Limonite', 'Other', 'Puerto Rico', 'United States: Puerto Rico', 'Leeward and Windward Islands ']\n",
    "        if country in drop_list:\n",
    "            drop_idx.append(idx)\n",
    "    df.drop(index=drop_idx, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Slice DataFrame until 'World' row\n",
    "    for idx in df.index:\n",
    "        country = df[df.columns[0]].iloc[idx]\n",
    "        if country == 'World':\n",
    "            world_idx = idx + 1\n",
    "    df = df[:world_idx]\n",
    "    \n",
    "    # Extract country names and clean them\n",
    "    countries = []\n",
    "    for country in df[df.columns[0]]:\n",
    "        country = country.strip(string.digits)\n",
    "        country = country.strip()\n",
    "        countries.append(country)\n",
    "    df['Country Name'] = countries\n",
    "    df.drop(columns=df.columns[0], inplace=True)\n",
    "    \n",
    "    # Assign ISO2 country codes and spatial scale\n",
    "    iso2 = []\n",
    "    spatial_scale = []\n",
    "    for country in df['Country Name']:\n",
    "        if country == 'Serbia and Montenegro':\n",
    "            iso2.append('CS')\n",
    "            spatial_scale.append('National')\n",
    "        elif country == 'Czechoslovakia':\n",
    "            iso2.append('CSK')\n",
    "            spatial_scale.append('National')\n",
    "        elif country == 'U.S.S.R.':\n",
    "            iso2.append('SU')\n",
    "            spatial_scale.append('National')\n",
    "        elif country == 'Yugoslavia':\n",
    "            iso2.append('YU')\n",
    "            spatial_scale.append('National')\n",
    "        elif country == 'Netherlands Antilles':\n",
    "            iso2.append('AN')\n",
    "            spatial_scale.append('National')\n",
    "        elif country == 'World':\n",
    "            iso2.append('World')\n",
    "            spatial_scale.append('Global')\n",
    "        else:\n",
    "            iso2.append(coco.convert(names=country, to='iso2'))\n",
    "            spatial_scale.append('National')\n",
    "    df['Country Code'] = iso2\n",
    "    df['Spatial Scale'] = spatial_scale\n",
    "    \n",
    "    # Add metadata columns\n",
    "    df['Data Source'] = 'USGS'\n",
    "    df['Unit'] = 'metric tons'\n",
    "    df['Metric'] = 'Annual production'\n",
    "    df['Technology Name'] = tech_name\n",
    "    df['ID'] = df['Technology Name'] + '_' + df['Metric'] + '_' + df['Country Code']\n",
    "    df.set_index('ID', inplace=True)\n",
    "    \n",
    "    # Remove irrelevant columns\n",
    "    omit = []\n",
    "    for col in df.columns:\n",
    "        if len(str(col)) > 4 or col == 'Unit':\n",
    "            omit.append(col)\n",
    "    empty_rows = df.drop(columns=omit)\n",
    "    empty_rows.dropna(how='all', inplace=True)\n",
    "    \n",
    "    # Remove rows with no data\n",
    "    na_idx = []\n",
    "    for country in df.index:\n",
    "        if country not in empty_rows.index:\n",
    "            na_idx.append(country)\n",
    "    df.drop(na_idx, inplace=True)\n",
    "    \n",
    "    # Remove duplicated entries for US/world (data available in another dataset)\n",
    "    dup_list = ['Primary Aluminum Production_Annual production_US', \n",
    "                'Primary Aluminum Production_Annual production_World',\n",
    "                'Primary Bauxite Production_Annual production_World','Cadmium Refining_Annual production_US',\n",
    "                'Cadmium Refining_Annual production_World','Lead_Annual production_US',\n",
    "                'Lead_Annual production_World','Salt Production_Annual production_US',\n",
    "                'Iron Ore_Annual production_US','Iron Ore_Annual production_World',\n",
    "                'Raw Steel Production_Annual production_US','Raw Steel Production_Annual production_World']\n",
    "    for idx in df.index:\n",
    "        if idx in dup_list:\n",
    "            df.drop(idx, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b827b5d1",
   "metadata": {},
   "source": [
    "Aluminum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa8a8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function\n",
    "aluminum = read_usgs_896('Primary Aluminum Production', (raw_data_path_usgs + '/ds896-aluminum.xlsx'), 'Aluminum, primary production')\n",
    "\n",
    "# save df to csv\n",
    "output_file = 'ds896_Aluminum.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "aluminum.to_csv(output_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "779e4671",
   "metadata": {},
   "source": [
    "Bauxite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93aa619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function\n",
    "bauxite = read_usgs_896('Primary Bauxite Production', (raw_data_path_usgs + '/ds896-aluminum.xlsx'), 'Bauxite')\n",
    "\n",
    "# Save df to csv\n",
    "output_file = 'ds896_Bauxite.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "bauxite.to_csv(output_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de36cea4",
   "metadata": {},
   "source": [
    "Cadmium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08bf96dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function\n",
    "cadmium = read_usgs_896('Cadmium Refining', (raw_data_path_usgs + '/ds896-cadmium.xlsx'))\n",
    "\n",
    "# Omit East/West Germany since there's only one year of data for each\n",
    "#cadmium = cadmium[(cadmium['Country Name']!='Germany: Eastern states') & (cadmium['Country Name']!='Germany: Western states')]\n",
    "\n",
    "# save df to csv\n",
    "output_file = 'ds896_CadmiumRefining.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "cadmium.to_csv(output_file_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a88566a",
   "metadata": {},
   "source": [
    "Copper (Mining and Refining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f332684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copper mining\n",
    "copper_mining = read_usgs_896('Copper|Mining', (raw_data_path_usgs + '/ds896-copper.xlsx'), 'Mine')\n",
    "copper_mining = copper_mining[copper_mining['    Mine production']=='Mine: Total']\n",
    "copper_mining.drop(columns='    Mine production', inplace=True)\n",
    "#save df to csv\n",
    "output_file = 'ds896_CopperMining.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "copper_mining.to_csv(output_file_path)\n",
    "\n",
    "# Copper refining\n",
    "\n",
    "copper_refining = read_usgs_896('Copper|Refining', (raw_data_path_usgs + '/ds896-copper.xlsx'), 'Refinery')\n",
    "copper_refining = copper_refining[copper_refining['Refinery production']=='Refinery: Total']\n",
    "copper_refining.drop(columns='Refinery production', inplace=True)\n",
    "#save df to csv\n",
    "output_file = 'ds896_CopperRefining.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "copper_refining.to_csv(output_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc8c4361",
   "metadata": {},
   "source": [
    "Iron ore and raw steel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a225bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iron ore \n",
    "iron = read_usgs_896('Iron Ore', (raw_data_path_usgs +'/ds896-iron-steel.xlsx'), 'Iron ore, gross weight')\n",
    "#iron = iron[(iron['Country Name']!='Germany: Western states')]\n",
    "# Save file\n",
    "output_file = 'ds896_IronOre.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "iron.to_csv(output_file_path)\n",
    "\n",
    "\n",
    "# Raw Steel\n",
    "steel = read_usgs_896('Raw Steel Production', (raw_data_path_usgs +'/ds896-iron-steel.xlsx'), 'Raw steel')\n",
    "#steel = steel[(steel['Country Name']!='Germany: Eastern states') & (steel['Country Name']!='Germany: Western states')]\n",
    "# Save file\n",
    "output_file = 'ds896_RawSteelProduction.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "steel.to_csv(output_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "664d6c06",
   "metadata": {},
   "source": [
    "Lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8aa6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead\n",
    "lead = read_usgs_896('Lead', (raw_data_path_usgs + '/ds896-lead.xlsx'), 'Mine')\n",
    "# lead = lead[lead['Country Name']!='Germany: Western states']\n",
    "output_file = 'ds896_Lead.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "lead.to_csv(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ddc6d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the Excel file for salt production\n",
    "salt = pd.read_excel((raw_data_path_usgs + '/ds896-salt.xlsx'), sheet_name=0, header=3,\n",
    "                     na_values=['XX','--', 'W', '(3/)', '(4/)','-- '])\n",
    "\n",
    "# Drop rows corresponding to irrelevant countries\n",
    "drop_idx = []\n",
    "for idx in salt.index:\n",
    "    country = salt[salt.columns[0]].iloc[idx]\n",
    "    drop_list = ['Limonite', 'Other', 'Puerto Rico', 'United States: Puerto Rico', 'Leeward and Windward Islands ']\n",
    "    if country in drop_list:\n",
    "        drop_idx.append(idx)\n",
    "salt.drop(index=drop_idx, inplace=True)\n",
    "salt.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Slice the DataFrame to include only relevant data\n",
    "for idx in salt.index:\n",
    "    country = salt[salt.columns[0]].iloc[idx]\n",
    "    if country == 'World':\n",
    "        world_idx = idx\n",
    "salt = salt[:world_idx]\n",
    "\n",
    "# Extract country names\n",
    "countries = []\n",
    "for country in salt[salt.columns[0]]:\n",
    "    country = country.strip(string.digits)\n",
    "    country = country.strip()\n",
    "    countries.append(country)\n",
    "salt['Country Name'] = countries\n",
    "\n",
    "# Drop columns and rows not needed\n",
    "salt = salt[(salt['Country Name']!='Germany: Eastern states') & (salt['Country Name']!='Germany: Western states')]\n",
    "salt.drop(columns=[salt.columns[0], 'Salt type'], inplace=True)\n",
    "\n",
    "# Summarize production by salt type for each country\n",
    "unique_countries = sorted(list(set(salt['Country Name'])))\n",
    "salt_type_sum = []\n",
    "for country in unique_countries:\n",
    "    dup_df = salt[salt['Country Name']==country].sum()\n",
    "    dup_df = dup_df[:-1]\n",
    "    val_list = []\n",
    "    for x in dup_df:\n",
    "        val_list.append(x)\n",
    "    val_list.append(country)\n",
    "    salt_type_sum.append(val_list)\n",
    "salt = pd.DataFrame(salt_type_sum, columns=salt.columns)\n",
    "\n",
    "# Assign ISO2 country codes and spatial scale\n",
    "iso2 = []\n",
    "spatial_scale = []\n",
    "for country in salt['Country Name']:\n",
    "    if country == 'Serbia and Montenegro':\n",
    "        iso2.append('CS')\n",
    "        spatial_scale.append('National')\n",
    "    elif country == 'Czechoslovakia':\n",
    "        iso2.append('CSK')\n",
    "        spatial_scale.append('National')\n",
    "    elif country == 'U.S.S.R.':\n",
    "        iso2.append('SU')\n",
    "        spatial_scale.append('National')\n",
    "    elif country == 'Yugoslavia':\n",
    "        iso2.append('YU')\n",
    "        spatial_scale.append('National')\n",
    "    elif country == 'World':\n",
    "        iso2.append('World')\n",
    "        spatial_scale.append('Global')\n",
    "    elif country == 'Netherlands Antilles':\n",
    "        iso2.append('AN')\n",
    "        spatial_scale.append('National')\n",
    "    else:\n",
    "        iso2.append(coco.convert(names=country, to='iso2'))\n",
    "        spatial_scale.append('National')\n",
    "salt['Country Code'] = iso2\n",
    "salt['Spatial Scale'] = spatial_scale\n",
    "\n",
    "# Add metadata columns\n",
    "salt['Data Source'] = 'USGS'\n",
    "salt['Unit'] = 'metric tons'\n",
    "salt['Metric'] = 'Annual production'\n",
    "salt['Technology Name'] = 'Salt Production'\n",
    "salt['ID'] = salt['Technology Name'] + '_' + salt['Metric'] + '_' + salt['Country Code']\n",
    "salt.set_index('ID', inplace=True)\n",
    "\n",
    "# Remove duplicated entries for US (data available in another dataset)\n",
    "salt.drop('Salt Production_Annual production_US', inplace=True)\n",
    "\n",
    "# Replace zero values with NaN\n",
    "salt.replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Define the output file path and save the processed DataFrame to a CSV file\n",
    "output_file = 'ds896_SaltProduction.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "salt.to_csv(output_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbb5aac4",
   "metadata": {},
   "source": [
    "Data source:\n",
    "- https://www.usgs.gov/centers/national-minerals-information-center/historical-statistics-mineral-and-material-commodities\n",
    "- Data Series 140\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e79105db",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_inflation_file = \"/A001RG3A086NBEA.xls\"\n",
    "target_inflation_filepath = inflation_data_path + target_inflation_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e375ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6912695457930007"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## adjusting for inflation from 1998 USD to 2022\n",
    "nipa = pd.read_excel(target_inflation_filepath, header=10)\n",
    "\n",
    "year_list = []\n",
    "for x in nipa['observation_date']:\n",
    "    x = int(str(x)[:4])\n",
    "    year_list.append(x)\n",
    "nipa['Year'] = year_list\n",
    "nipa.set_index('Year', drop=True, inplace=True)\n",
    "nipa.drop(columns='observation_date', inplace=True)\n",
    "nipa = nipa.transpose()\n",
    "\n",
    "infl_1998_2022 = float(nipa[2022]/nipa[1998])\n",
    "infl_1998_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36c643e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_usgs_140(tech_name, file_name, sheet=0, header=4,\n",
    "                  col_names=['Year','Production','Unit value (98$/t)','World production']):\n",
    "    \"\"\"\n",
    "    Reads data from the USGS 140 dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - tech_name (str): Name of the technology.\n",
    "    - file_name (str): Path to the Excel file containing the data.\n",
    "    - sheet (int): Index or name of the sheet to read.\n",
    "    - header (int): Row number to use as the column names.\n",
    "    - col_names (list): List of column names to read from the Excel file.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Processed DataFrame containing the data.\n",
    "    \"\"\"\n",
    "    # Read data from the Excel file\n",
    "    df = pd.read_excel(file_name, sheet_name=sheet, header=header, usecols=col_names, \n",
    "                       na_values=['XX','--', 'W', '(3/)', '(4/)','-- '])\n",
    "    \n",
    "    # Find the index where the numeric data ends\n",
    "    end_idx = None\n",
    "    for idx in df.index:\n",
    "        year = df['Year'].iloc[idx]\n",
    "        if type(year) != int:\n",
    "            end_idx = idx\n",
    "            break\n",
    "    \n",
    "    # Slice the DataFrame to include only the numeric data\n",
    "    df = df[:end_idx]\n",
    "    \n",
    "    # Set 'Year' column as the index\n",
    "    df.set_index('Year', drop=True, inplace=True)\n",
    "    \n",
    "    # Transpose the DataFrame\n",
    "    df = df.transpose()\n",
    "    \n",
    "    # Adjust production values by inflation rate\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col] * infl_1998_2022\n",
    "    \n",
    "    # Add metadata columns\n",
    "    df['Technology Name'] = tech_name\n",
    "    df['Data Source'] = 'USGS'\n",
    "    df['Country Name'] = ['United States', 'World', 'World']\n",
    "    df['Country Code'] = ['US', 'World', 'World']\n",
    "    df['Spatial Scale'] = ['National', 'Global', 'Global']\n",
    "    df['Unit'] = ['metric tons', '2022 USD/metric ton', 'metric tons']\n",
    "    df['Metric'] = ['Annual production', 'Price', 'Annual production']\n",
    "    \n",
    "    # Create unique identifier for each row\n",
    "    df['ID'] = df['Technology Name'] + '_' + df['Metric'] + '_' + df['Country Code']\n",
    "    \n",
    "    # Set 'ID' column as the index\n",
    "    df.set_index('ID', drop=True, inplace=True)\n",
    "    \n",
    "    # Remove column name\n",
    "    df.columns.name = None\n",
    "    \n",
    "    # Return the processed DataFrame\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a779867",
   "metadata": {},
   "source": [
    "Raw Steel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe2a9370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw steel\n",
    "steel_ds140 = read_usgs_140('Raw Steel Production', (raw_data_path_usgs + '/ds140-iron-steel-2019.xlsx'), header=5,\n",
    "                            sheet='Steel',\n",
    "                            col_names=['Year','Raw steel production','Unit value (98$/t)','World production'])\n",
    "\n",
    "# save file\n",
    "\n",
    "\n",
    "output_file = 'ds140_RawSteelProduction.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "steel_ds140.to_csv(output_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce2f7f19",
   "metadata": {},
   "source": [
    "Cadmium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72b443d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cadmium\n",
    "cadmium_ds140 = read_usgs_140('Cadmium Refining', (raw_data_path_usgs + '/ds140-cadmium-2019.xlsx'), \n",
    "                             col_names=['Year','Production','Unit value (98 $/t)','World production'])\n",
    "\n",
    "# save file\n",
    "output_file = 'ds140_CadmiumRefining.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "cadmium_ds140.to_csv(output_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c142ccf",
   "metadata": {},
   "source": [
    "Iron Ore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1c2e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iron ore\n",
    "iron_ds140 = read_usgs_140('Iron Ore', (raw_data_path_usgs + '/ds140-iron-ore-2019.xlsx'),\n",
    "                          col_names=['Year','Production','Unit value (98$/t) ','World production'])\n",
    "\n",
    "# save file\n",
    "output_file = 'ds140_IronOre.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "iron_ds140.to_csv(output_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19203550",
   "metadata": {},
   "source": [
    "Lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a3fdd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lead\n",
    "lead_ds140 = read_usgs_140('Lead', (raw_data_path_usgs + '/ds140-lead-2018.xlsx'),\n",
    "                          col_names=['Year','Primary production','Unit value (98$/t)','World production'])\n",
    "\n",
    "# save file\n",
    "output_file = 'ds140_Lead.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "lead_ds140.to_csv(output_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c8fc444",
   "metadata": {},
   "source": [
    "Primary Aluminum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edc4e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# primary aluminum\n",
    "aluminum_ds140 = read_usgs_140('Primary Aluminum Production', (raw_data_path_usgs + '/ds140-aluminum-2019.xlsx'),\n",
    "                          col_names=['Year','Primary production','Unit value (98$/t)','World production'])\n",
    "\n",
    "\n",
    "# save file\n",
    "output_file = 'ds140_Aluminum.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "aluminum_ds140.to_csv(output_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8079aab9",
   "metadata": {},
   "source": [
    "Graphite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd46b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphite\n",
    "graphite = read_usgs_140('Graphite', (raw_data_path_usgs + '/ds140-graphite-2019.xlsx'))\n",
    "\n",
    "\n",
    "# save file\n",
    "output_file = 'ds140_Graphite.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "graphite.to_csv(output_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36e71ab9",
   "metadata": {},
   "source": [
    "Cobalt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a1cbb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cobalt\n",
    "cobalt = read_usgs_140('Cobalt', (raw_data_path_usgs + '/ds140-cobalt-2019.xlsx'),\n",
    "                    col_names=['Year','Primary production','Unit value (98$/t)','World mine production'])\n",
    "\n",
    "   \n",
    "\n",
    "# save file\n",
    "output_file = 'ds140_Cobalt.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "cobalt.to_csv(output_file_path)             \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bce6d44",
   "metadata": {},
   "source": [
    "Lithium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f6f1773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lithium\n",
    "lithium = read_usgs_140('Lithium Mine Production', (raw_data_path_usgs + '/ds140-lithium-2019.xlsx'),\n",
    "                    col_names=['Year','Production','Unit value (98$/t)','World production (gross weight)'])\n",
    "\n",
    "# save file\n",
    "output_file = 'ds140_Lithium.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "lithium.to_csv(output_file_path)           \n",
    "                    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "079c359c",
   "metadata": {},
   "source": [
    "Rare Earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf8b63ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rare earth\n",
    "rare_earth = read_usgs_140('Rare Earth Mine Production', (raw_data_path_usgs + '/ds140-rare-earths-2019.xlsx'))\n",
    "\n",
    "# save file\n",
    "output_file = 'ds140_RareEarth.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "rare_earth.to_csv(output_file_path)      \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94e8006d",
   "metadata": {},
   "source": [
    "Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a681c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# silver\n",
    "silver = read_usgs_140('Silver Production', (raw_data_path_usgs + '/ds140-silver-2018.xlsx'),\n",
    "                    col_names=['Year','Mine production','Unit value (98$/t)','World production'])\n",
    "\n",
    "# save file\n",
    "output_file = 'ds140_Silver.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "silver.to_csv(output_file_path)     \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a8a1115",
   "metadata": {},
   "source": [
    "Tin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00db437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tin\n",
    "tin = read_usgs_140('Tin Production', (raw_data_path_usgs + '/ds140-tin-2019.xlsx'),\n",
    "                    col_names=['Year','Primary production','Unit value (98$/t)','World production'])\n",
    "                    \n",
    " \n",
    "# save file\n",
    "output_file = 'ds140_Tin.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "tin.to_csv(output_file_path)     \n",
    "                   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40cfe77f",
   "metadata": {},
   "source": [
    "Cement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2ba4485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cement\n",
    "cement = read_usgs_140('Cement', (raw_data_path_usgs + '/ds140-cement-2019.xlsx'))\n",
    "\n",
    "# save file\n",
    "output_file = 'ds140_Cement.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "cement.to_csv(output_file_path)     \n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc1902ee",
   "metadata": {},
   "source": [
    "Primary Copper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dea448bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary copper\n",
    "copper = read_usgs_140('Primary Copper', (raw_data_path_usgs + '/ds140-copper-2018.xlsx'), \n",
    "             col_names=['Year','Primary production','Unit value (98$/t)','World production'])\n",
    "\n",
    "  \n",
    "# save file\n",
    "output_file = 'ds140_Copper.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "copper.to_csv(output_file_path)               "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "477a051e",
   "metadata": {},
   "source": [
    "Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e079006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gold\n",
    "gold = read_usgs_140('Gold Production', (raw_data_path_usgs + '/ds140-gold-2018.xlsx'), \n",
    "             col_names=['Year','Primary production','Unit value (98$/t)','World production'])\n",
    "\n",
    "      \n",
    "# save file\n",
    "output_file = 'ds140_Gold.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "gold.to_csv(output_file_path)            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c48df06",
   "metadata": {},
   "source": [
    "Nickel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64ce49b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nickel\n",
    "nickel = read_usgs_140('Nickel Production', (raw_data_path_usgs + '/ds140-nickel-2018_1.xlsx'), \n",
    "             col_names=['Year','Primary production','Unit value (98$/t)','World production'])\n",
    "\n",
    "      \n",
    "# save file\n",
    "output_file = 'ds140_Nickel.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "nickel.to_csv(output_file_path)           "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "721a6b1c",
   "metadata": {},
   "source": [
    "Sand and Gravel (Construction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0862788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sand and gravel (construction)\n",
    "sand_gravel_construction = read_usgs_140('Sand and Gravel|Construction', \n",
    "                                         (raw_data_path_usgs + '/ds140-sand-gravel-construction-2019.xlsx'))\n",
    "\n",
    "          \n",
    "# save file\n",
    "output_file = 'ds140_SandGravelConstruction.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "sand_gravel_construction.to_csv(output_file_path)                                  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d76b6e21",
   "metadata": {},
   "source": [
    "Sand and Gravel Industrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96419898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sand and gravel (industrial)\n",
    "sand_gravel_industrial = read_usgs_140('Sand and Gravel|Industrial', \n",
    "                                         (raw_data_path_usgs + '/ds140-sand-industrial-2019.xlsx'))\n",
    "           \n",
    "# save file\n",
    "output_file = 'ds140_SandGravelIndustrial.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "sand_gravel_industrial.to_csv(output_file_path)                                         "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c21d37b5",
   "metadata": {},
   "source": [
    "Zinc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a72a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zinc\n",
    "zinc = read_usgs_140('Zinc Production', (raw_data_path_usgs + '/ds140-zinc-2019.xlsx'),\n",
    "                    col_names=['Year',' Primary production','Unit value (98$/t)','World production'])\n",
    "                         \n",
    "# save file\n",
    "output_file = 'ds140_Zinc.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "zinc.to_csv(output_file_path)         \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27d2f439",
   "metadata": {},
   "source": [
    "Salt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d9c056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salt\n",
    "salt_ds140 = read_usgs_140('Salt Production', (raw_data_path_usgs +'/ds140-2017-salt.xlsx'),\n",
    "                    col_names=['Year','Production','Unit value  (98$/t)','World production'])\n",
    "                                          \n",
    "# save file\n",
    "output_file = 'ds140_Salt.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "salt_ds140.to_csv(output_file_path)         \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5400895",
   "metadata": {},
   "source": [
    "Bauxite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ef5ee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bauxite\n",
    "bauxite_ds140 = read_usgs_140('Primary Bauxite Production', (raw_data_path_usgs + '/ds140-bauxite-alumina-2019.xlsx'),\n",
    "                          col_names=['Year','Production','Unit value (98$/t)','World production'])\n",
    "                                                           \n",
    "# save file\n",
    "output_file = 'ds140_Bauxite.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "bauxite_ds140.to_csv(output_file_path)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468201ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
