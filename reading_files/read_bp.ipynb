{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60659557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import string\n",
    "import country_converter as coco\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "511e8288",
   "metadata": {},
   "source": [
    "Original data sources\n",
    "- https://www.bp.com/en/global/corporate/energy-economics/statistical-review-of-world-energy.html\n",
    "- Statistical Review of World Energy - all data, 1965-2021\n",
    "- https://www.bp.com/content/dam/bp/business-sites/en/global/corporate/xlsx/energy-economics/statistical-review/bp-stats-review-2022-all-data.xlsx \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1f0b399",
   "metadata": {},
   "source": [
    "Find file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55e391cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/jennagreene/Documents/GitHub/HATCH_data/reading_files\n"
     ]
    }
   ],
   "source": [
    "## Get current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "## Find path to raw data (for the raw files)\n",
    "raw_data_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'raw_data'))\n",
    "\n",
    "## Find path to folder for saving cleaned csv\n",
    "cleaned_data_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'cleaned_data'))\n",
    "\n",
    "## Find path to folder for inflation\n",
    "inflation_data_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'inflation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "789b5793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and read the CSV file from the raw_data folder\n",
    "target_file = 'bp-stats-review-2022-all-data.xlsx'\n",
    "target_file_path = os.path.join(raw_data_path, target_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c94ba552",
   "metadata": {},
   "source": [
    "Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47b92c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bp(sheet):\n",
    "\n",
    "    # Read data from Excel file into DataFrame\n",
    "    df = pd.read_excel(target_file_path, \n",
    "                       sheet_name=sheet, header=2, \n",
    "                       index_col=0, na_values=['-', '^','♦'])\n",
    "    \n",
    "    # Remove non-integer columns\n",
    "    omit = []\n",
    "    for col in df.columns:\n",
    "        if type(col) != int:\n",
    "            omit.append(col)\n",
    "    df.drop(columns=omit, inplace=True)\n",
    "\n",
    "    # Drop rows with all NaN values\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    \n",
    "    # Extract country name from index\n",
    "    idx = []\n",
    "    for country in df.index:\n",
    "        x = country.strip(string.digits)\n",
    "        idx.append(x)\n",
    "    df['Country Name'] = idx\n",
    "\n",
    "    # Extract unit from index name\n",
    "    unit = df.index.name.rstrip('*')\n",
    "    unit = unit.strip(string.digits)\n",
    "    df['Unit'] = unit\n",
    "    \n",
    "    # Add data source and spatial scale\n",
    "    df['Data Source'] = 'BP'\n",
    "    spatial_scale = []\n",
    "    for country in df.index:\n",
    "        strings = ['Total', 'Rest of World', 'Other', 'European Union', 'OECD', 'Central America', \\\n",
    "                   'Eastern Africa', 'Middle Africa', 'Western Africa', 'OPEC']\n",
    "        for s in strings:\n",
    "            if s in country and country != 'Total World':\n",
    "                df.drop(country, inplace=True)\n",
    "    iso2 = []\n",
    "    for country in df.index:\n",
    "        if country=='USSR':\n",
    "            iso2.append('SU')\n",
    "            spatial_scale.append('National')\n",
    "        elif country=='Netherlands Antilles':\n",
    "            iso2.append('AN')\n",
    "            spatial_scale.append('National')\n",
    "        elif country=='Total World':\n",
    "            iso2.append('World')\n",
    "            spatial_scale.append('Global')\n",
    "        else:\n",
    "            iso2.append(coco.convert(names=country, to='iso2'))\n",
    "            spatial_scale.append('National')\n",
    "    df.replace('Total World', 'World', inplace=True)\n",
    "    df['Spatial Scale'] = spatial_scale\n",
    "    df['Country Code'] = iso2\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Replace units with standardized names\n",
    "    df.replace({'Petajoules':'petajoules','Million tonnes':'million metric tons',\n",
    "                'Million tonnes ':'million metric tons','million tonnes ':'million metric tons',\n",
    "                'Thousand tonnes':'thousand metric tons','Tonnes':'metric tons',\n",
    "                'Terawatt-hours':'TWh','Billion cubic metres':'billion cubic metres',\n",
    "               'Thousand barrels daily':'thousand barrels/day'}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8878827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tech_name(df, tech):\n",
    "    # Add a column for the technology name\n",
    "    df['Technology Name'] = tech\n",
    "\n",
    "    # Combine technology name, metric, and country code to form unique IDs\n",
    "    df['ID'] = df['Technology Name'] + '_' + df['Metric'] + '_' + df['Country Code']\n",
    "\n",
    "    # Set the index of the DataFrame to the ID column\n",
    "    df.set_index('ID', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4525ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e98b28a",
   "metadata": {},
   "source": [
    "Oil Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "742b2dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_oil_production = read_bp('Oil Production - Tonnes')\n",
    "bp_oil_production['Metric'] = 'Annual Production'\n",
    "bp_oil_production = tech_name(bp_oil_production, 'Oil Production')\n",
    "bp.append(bp_oil_production)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fc9d56c",
   "metadata": {},
   "source": [
    "Oil refining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "469c6035",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_oil_refining = read_bp('Oil - Refining capacity')\n",
    "bp_oil_refining['Metric'] = 'Total Capacity'\n",
    "bp_oil_refining = tech_name(bp_oil_refining, 'Oil Refining Capacity')\n",
    "bp.append(bp_oil_refining)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06c203a1",
   "metadata": {},
   "source": [
    "Gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "daf4d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_gas = read_bp('Gas Production - Bcm')\n",
    "bp_gas['Metric'] = 'Annual Production'\n",
    "bp_gas = tech_name(bp_gas, 'Natural Gas Production')\n",
    "bp.append(bp_gas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8481f44",
   "metadata": {},
   "source": [
    "Coal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9960fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_coal = read_bp('Coal Production - Tonnes')\n",
    "bp_coal['Metric'] = 'Annual Production'\n",
    "bp_coal = tech_name(bp_coal, 'Coal Production')\n",
    "bp.append(bp_coal)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80eac12e",
   "metadata": {},
   "source": [
    "Nuclear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b00aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_nuclear = read_bp('Nuclear Generation - TWh')\n",
    "bp_nuclear['Metric'] = 'Annual Production'\n",
    "bp_nuclear = tech_name(bp_nuclear, 'Nuclear Energy')\n",
    "bp.append(bp_nuclear)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1ea6b42",
   "metadata": {},
   "source": [
    "Hydro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f30e12ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_hydro = read_bp('Hydro Generation - TWh')\n",
    "bp_hydro['Metric'] = 'Annual Production'\n",
    "bp_hydro = tech_name(bp_hydro, 'Hydroelectricity')\n",
    "bp.append(bp_hydro)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07d03690",
   "metadata": {},
   "source": [
    "Renewables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44dbb558",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_renewable = read_bp('Renewable power - TWh')\n",
    "bp_renewable['Metric'] = 'Annual Production'\n",
    "bp_renewable = tech_name(bp_renewable, 'Renewable Power')\n",
    "bp.append(bp_renewable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08289cff",
   "metadata": {},
   "source": [
    "Electricity generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32ca4aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_electricity_gen = read_bp('Electricity Generation')\n",
    "bp_electricity_gen['Metric'] = 'Annual Production'\n",
    "bp_electricity_gen = tech_name(bp_electricity_gen, 'Electricity')\n",
    "bp.append(bp_electricity_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e99169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bp_lithium = read_bp('Lithium Production-Reserves')\n",
    "# bp_lithium['Metric'] = 'Annual Production'\n",
    "# bp_lithium = tech_name(bp_lithium, 'Lithium Mine Production')\n",
    "# bp.append(bp_lithium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8fcb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bp_cobalt = read_bp('Cobalt Production-Reserves')\n",
    "# bp_cobalt['Metric'] = 'Annual Production'\n",
    "# bp_cobalt = tech_name(bp_cobalt, 'Cobalt Mine Production')\n",
    "# bp.append(bp_cobalt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9263ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bp_rare_earth = read_bp('Rare Earth Production-Reserves')\n",
    "# bp_rare_earth['Metric'] = 'Annual Production'\n",
    "# bp_rare_earth = tech_name(bp_rare_earth, 'Rare Earth Mine Production')\n",
    "# bp.append(bp_rare_earth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc9374fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bp_graphite = read_bp('Graphite Production-Reserves')\n",
    "# bp_graphite['Metric'] = 'Annual Production'\n",
    "# bp_graphite = tech_name(bp_graphite, 'Graphite Mine Production')\n",
    "# bp.append(bp_graphite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43c08bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bp2(sheet):\n",
    "    # Define list of missing values to be treated as NaN\n",
    "    missing_values = ['-', '^','♦']\n",
    "    \n",
    "    # Read data from Excel file into DataFrame\n",
    "    df = pd.read_excel(target_file_path, sheet_name=sheet, header=2, index_col=0, \n",
    "                       na_values=missing_values, skipfooter=40)\n",
    "    \n",
    "    # Remove non-integer columns\n",
    "    omit = []\n",
    "    for col in df.columns:\n",
    "        if type(col) != int:\n",
    "            omit.append(col)\n",
    "    df.drop(columns=omit, inplace=True)\n",
    "    \n",
    "    # Drop rows with all NaN values\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    \n",
    "    # Extract country name from index\n",
    "    idx = []\n",
    "    for country in df.index:\n",
    "        x = country.strip(string.digits)\n",
    "        idx.append(x)\n",
    "    df['Country Name'] = idx\n",
    "    \n",
    "    # Extract unit from index name\n",
    "    unit = df.index.name.rstrip('*')\n",
    "    unit = unit.strip(string.digits)\n",
    "    df['Unit'] = unit\n",
    "    \n",
    "    # Add data source and spatial scale\n",
    "    df['Data Source'] = 'BP'\n",
    "    df['Spatial Scale'] = 'National'\n",
    "    \n",
    "    # Drop rows representing aggregated regions\n",
    "    for country in df.index:\n",
    "        strings = ['Total', 'Rest of World', 'Other', 'European Union', 'OECD', 'Central America',\n",
    "                   'Eastern Africa', 'Middle Africa', 'Western Africa', 'OPEC']\n",
    "        for s in strings:\n",
    "            if s in country:\n",
    "                df.drop(country, inplace=True)\n",
    "    \n",
    "    # Map country names to ISO2 country codes\n",
    "    iso2 = []\n",
    "    for country in df.index:\n",
    "        if country == 'USSR':\n",
    "            iso2.append('SU')\n",
    "        elif country == 'Netherlands Antilles':\n",
    "            iso2.append('AN')\n",
    "        else:\n",
    "            iso2.append(coco.convert(names=country, to='iso2'))\n",
    "    df['Country Code'] = iso2\n",
    "    \n",
    "    # Reset the index of the DataFrame\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Replace units with standardized names\n",
    "    df.replace({'Petajoules':'petajoules','Million tonnes':'million metric tons',\n",
    "                'Million tonnes ':'million metric tons','million tonnes ':'million metric tons',\n",
    "                'Thousand tonnes':'thousand metric tons','Tonnes':'metric tons',\n",
    "                'Terawatt-hours':'TWh','Billion cubic metres':'billion cubic metres',\n",
    "               'Thousand barrels daily':'thousand barrels/day'}, inplace=True)\n",
    "    \n",
    "    # Return the processed DataFrame\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ec2e45c",
   "metadata": {},
   "source": [
    "Biofuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2b0a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_biofuels = read_bp2('Biofuels production - PJ')\n",
    "bp_biofuels['Metric'] = 'Annual Production'\n",
    "bp_biofuels = tech_name(bp_biofuels, 'Biofuels Production')\n",
    "bp.append(bp_biofuels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "474fe6fb",
   "metadata": {},
   "source": [
    "Combine all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f632b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = pd.concat(bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0438e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store non-integer column names\n",
    "omit = []\n",
    "\n",
    "# Iterate through the column names of the DataFrame\n",
    "for col in bp.columns:\n",
    "    # Check if the column name is not an integer\n",
    "    if type(col) != int:\n",
    "        # If it's not an integer, add it to the list of columns to omit\n",
    "        omit.append(col)\n",
    "\n",
    "# Drop columns with non-integer names from the DataFrame\n",
    "empty_rows = bp.drop(columns=omit)\n",
    "\n",
    "# Drop rows with all NaN values\n",
    "empty_rows.dropna(how='all', inplace=True)\n",
    "\n",
    "# Initialize an empty list to store index labels of rows to be dropped\n",
    "na_idx = []\n",
    "\n",
    "# Iterate through the index labels of the original DataFrame\n",
    "for country in bp.index:\n",
    "    # Check if the country index label is not present in the modified DataFrame\n",
    "    if country not in empty_rows.index:\n",
    "        # If it's not present, add it to the list of index labels to be dropped\n",
    "        na_idx.append(country)\n",
    "\n",
    "# Drop rows with index labels stored in na_idx list from the original DataFrame\n",
    "bp.drop(na_idx, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7325e91d",
   "metadata": {},
   "source": [
    "Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10a7c527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to: /Users/jennagreene/Documents/GitHub/HATCH_data/cleaned_data/bp.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = 'bp.csv'\n",
    "output_file_path = os.path.join(cleaned_data_path, output_file)\n",
    "\n",
    "bp.to_csv(output_file_path)\n",
    "print(\"Data saved to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d318cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
